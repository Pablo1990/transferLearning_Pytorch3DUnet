{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74440e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "import h5py\n",
    "import tifffile as tiff\n",
    "from PIL.TiffTags import TAGS\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf098e59",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6605e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_parameters(rawFilePath):\n",
    "    '''Obtain raw image parameters: zSpacing, xResolution and yResolution from TIFF'''\n",
    "    \n",
    "    rawImg = tiff.TiffFile(rawFilePath);\n",
    "    try:\n",
    "        zSpacing = rawImg.imagej_metadata['spacing'];\n",
    "    except Exception as e:\n",
    "        zSpacing = 1;\n",
    "    \n",
    "    if rawImg.imagej_metadata['unit'] == 'micron':\n",
    "        measurementsInMicrons = True;\n",
    "        \n",
    "    rawImg = Image.open(rawFilePath)\n",
    "    \n",
    "    if TAGS[282] == 'XResolution':\n",
    "        xResolution = 1/rawImg.tag_v2[282];\n",
    "        \n",
    "    if TAGS[283] == 'YResolution':\n",
    "        yResolution = 1/rawImg.tag_v2[283];\n",
    "        \n",
    "    if measurementsInMicrons:\n",
    "        #To nanometers\n",
    "        zSpacing=zSpacing*1000;\n",
    "        xResolution=xResolution*1000;\n",
    "        yResolution=yResolution*1000;\n",
    "\n",
    "    return zSpacing, xResolution, yResolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072a8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_seg_images(rawFilePath, segFilePath, resize_img=False):\n",
    "    '''Read segmented image to remove first biggest label and obtain list of cell properties'''\n",
    "    \n",
    "    if rawFilePath.endswith('tif') or rawFilePath.endswith('tiff'):\n",
    "        rawImg = io.imread(rawFilePath)\n",
    "        segmentedImg = io.imread(segFilePath)\n",
    "    \n",
    "    if rawFilePath.endswith('h5'):\n",
    "        rawImgh5 = h5py.File(rawFilePath, 'r')\n",
    "        rawImg = np.array(rawImgh5.get('raw'))\n",
    "\n",
    "        segmentedImgh5 = h5py.File(segFilePath, 'r')\n",
    "        segmentedImg = np.array(segmentedImgh5.get('label'))\n",
    "        \n",
    "    segmentedImg = segmentedImg - 1;\n",
    "    \n",
    "    if resize_img == True:\n",
    "            rawImg = transform.resize(rawImg, (rawImg.shape[0], 512, 512),\n",
    "                            order=0, preserve_range=True, anti_aliasing=False).astype(np.uint32)\n",
    "            segmentedImg = transform.resize(segmentedImg, (segmentedImg.shape[0], 512, 512),\n",
    "                                  order=0, preserve_range=True, anti_aliasing=False).astype(np.uint32)  \n",
    "    #uniqueIds=np.unique(segmentedImg)\n",
    "    #maxId = uniqueIds.max()\n",
    "     \n",
    "    #props = measure.regionprops(segmentedImg)\n",
    "\n",
    "    return rawImg, segmentedImg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1ab97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:5: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_27005/984239975.py:5: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if segImg is not 0:\n"
     ]
    }
   ],
   "source": [
    "def save_hdf5(h5FileName, rawImg, segImg, zSpacing, xResolution, yResolution):\n",
    "    '''Saves postprocessed image as HDF5'''\n",
    "    \n",
    "    h5pyFile = h5py.File(h5FileName, \"w\")\n",
    "    if segImg is not 0:\n",
    "        segmentation = h5pyFile.create_dataset(\"label\", data=segImg, dtype='uint16')\n",
    "        segmentation.attrs['element_size_um'] = [zSpacing, yResolution.numerator,yResolution.denominator, xResolution.numerator,xResolution.denominator]\n",
    "    \n",
    "    \n",
    "    rawH5 = h5pyFile.create_dataset('raw', data=rawImg, dtype='uint8')\n",
    "    rawH5.attrs['element_size_um'] = [zSpacing, float(yResolution.numerator/yResolution.denominator), float(xResolution.numerator/xResolution.denominator)]\n",
    "    \n",
    "    h5pyFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bcd8c",
   "metadata": {},
   "source": [
    "# User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5add538",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = '/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/'\n",
    "raw_dir = [files_path + 'raw/']\n",
    "datasets_dir = files_path + 'inputDataset/'\n",
    "datasetsToSplit = [datasets_dir + 'all/']\n",
    "train_dir = files_path + 'inputDataset/training/'\n",
    "test_dir = files_path + 'inputDataset/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77344963",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c3930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir exists\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/raw/\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t2.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t4.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t6.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t8.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t10.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t11.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t11.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t9.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t2.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t5.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t6.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t3.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t8.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t7.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t4.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc1_decon_c1_t7.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t10.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t1.h5\n",
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/toPredict/Disc2_decon_c1_t3.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(train_dir)\n",
    "except OSError as exc:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(test_dir)\n",
    "except OSError as exc:\n",
    "    pass\n",
    "\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "try:\n",
    "    os.mkdir(files_path + 'raw/')\n",
    "except OSError as exc:\n",
    "    print('Dir exists')\n",
    "\n",
    "for currentDir in raw_dir:\n",
    "    print(currentDir)\n",
    "    for root, subdirs, files in os.walk(currentDir):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.tif'):\n",
    "                fullFileName = root + filename;\n",
    "                fullFileName_seg = fullFileName.replace('raw', 'segmented')\n",
    "                fullFileName_seg = fullFileName_seg.replace('.tif', '_masks.tif')\n",
    "                if os.path.exists(fullFileName_seg):\n",
    "                    rawImg, segmentedImg = load_raw_seg_images(fullFileName, fullFileName_seg)\n",
    "                    zSpacing, xResolution, yResolution = raw_parameters(fullFileName)\n",
    "                    h5FileName = datasets_dir + 'all/' + filename.replace('.tif', '.h5')\n",
    "                    save_hdf5(h5FileName, rawImg, segmentedImg, zSpacing, xResolution, yResolution)\n",
    "                else:\n",
    "                    rawImg = io.imread(fullFileName)\n",
    "                    zSpacing, xResolution, yResolution = raw_parameters(fullFileName)\n",
    "                    h5FileName = datasets_dir + 'toPredict/' + filename.replace('.tif', '.h5')\n",
    "                    print(h5FileName)\n",
    "                    save_hdf5(h5FileName, rawImg, [0], zSpacing, xResolution, yResolution)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03b6cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/all/\n"
     ]
    }
   ],
   "source": [
    "allFileNames = list()\n",
    "for currentDir in datasetsToSplit:\n",
    "    print(currentDir)\n",
    "    for root, subdirs, files in os.walk(currentDir):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.h5'):\n",
    "                currentFileName = root + '/' + filename;\n",
    "                allFileNames.append(currentFileName)\n",
    "\n",
    "# Split into validation and test, first\n",
    "train_data, test_data = train_test_split(allFileNames, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6aa34438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/all//Disc1_decon_c1_t9.h5',\n",
       " '/media/pablo/d7c61090-024c-469a-930c-f5ada47fb049/PabloVicenteMunuera/transferLearning_Pytorch3DUnet/data/inputDataset/all//Disc1_decon_c1_t5.h5']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1659fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files onto different dirs\n",
    "for train_file in train_data:\n",
    "    shutil.copy2(train_file, train_file.replace('/all/', '/training/'))\n",
    "    \n",
    "# Save files onto different dirs\n",
    "for test_file in test_data:\n",
    "    shutil.copy2(train_file, train_file.replace('/all/', '/validation/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
